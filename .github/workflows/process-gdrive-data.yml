# .github/workflows/process-gdrive-data.yml

name: Process GDrive Data

on:
  schedule:
    # Runs at 10:45 AM IST (which is 05:15 UTC) every day.
    - cron: '15 5 * * *'
  workflow_dispatch: # Allows you to manually run the workflow

jobs:
  run-gdrive-processor:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      # -----------------------------------------------------------------
      # --- IMPROVED DEPENDENCY INSTALLATION ---
      # -----------------------------------------------------------------

      - name: Cache pip dependencies
        # This step speeds up builds by caching packages between runs
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          # Create a new cache if requirements.txt changes
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install Python dependencies
        run: |
          # Upgrade pip to ensure you have the latest installer
          python -m pip install --upgrade pip
          # Install dependencies from a requirements file
          # This is more reliable and manageable
          pip install -r requirements.txt
      
      # -----------------------------------------------------------------

      - name: Run the GDrive processing script
        env:
          # This securely passes your service account key to the Python script
          GCP_SA_KEY: ${{ secrets.GCP_SA_KEY }}
        # Ensure the python script file is named 'gdrive_processor.py'
        run: python gdrive_processor.py
